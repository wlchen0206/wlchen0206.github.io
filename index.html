---
layout: academic
math: true
about: |
  <p>
    I am a 2nd-year CS PhD student at <a href="https://engineering.virginia.edu/department/computer-science" target='_blank'>University of Virginia</a>.
    Previously, I was a student researcher at <a href="https://research.google/" target='_blank'>Google</a>.
    I am fortunate to be advised by <a href="https://yumeng5.github.io/" target='_blank'>Yu Meng</a> and am grateful to be supported by UVA Provost's Fellowship and UVA Computer Science Scholar Fellowship.
  </p>
  <p>
    Nowadays, I think about
    <i>(1)</i> how to measure LLM's reasoning effort beyond superficial features like token length, and
    <i>(2)</i> how to ensure LLM-based evaluators succeed in non-trivially verifiable domains by grounding their behavior in insights drawn from verifiable tasks.
  </p>
  <!-- <p>
      I spent a summer as a student researcher at Google MTV.
      In the past, I worked with <a href='https://scholar.google.com/citations?user=jQLg-_UAAAAJ&hl=en' target='_blank'>Yun-Nung (Vivian) Chen</a> and <a href='https://nlg.csie.ntu.edu.tw/advisor.php' target='_blank'></a>Hsin-Hsi Chen</a> at <a href='https://www.ntu.edu.tw/english/' target='_blank'>National Taiwan University</a>.
  </p> -->
---

<div style="background-color: #fff5e6; border: 2px dotted #ff8c00; padding: 10px; margin: 20px 0; display: inline-block; border-radius: 8px;">
  <p style="margin: 0; font-size: 14px; color: #333;">I am actively seeking research internship opportunities for Summer 2026.</p>
</div>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:16px 2.5%;width:100%;vertical-align:middle">
      <h2 id="publications">Select Research</h2>
      <p style="margin-top: 8px; margin-bottom: 0;">*equal contribution</p>
    </td>
  </tr>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <td style="padding:8px 2.5%;width:100%;vertical-align:middle">
      <span class="papertitle">Do LLM Evaluators Prefer Themselves for a Reason?</span>
      <br>
      <i><strong>Wei-Lin Chen, </strong><span style="color:#615d5a;">Zhepei Wei, </span><span style="color:#615d5a;">Xinyu Zhu, </span><span style="color:#615d5a;">Shi Feng, </span><span style="color:#615d5a;">Yu Meng</span></i>
      <br>
      <em>Preprint</em>
      <br>
      <a href='https://arxiv.org/pdf/2504.03846' target='_blank'>arXiv</a> /
      <a href='https://x.com/WeiLin__Chen/status/1910186987883266093' target='_blank'>thread</a>
    </td>
  </tr>
  <tr>
    <td style="padding:8px 2.5%;width:100%;vertical-align:middle">
      <span class="papertitle">The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning</span>
      <br>
      <i><span style="color:#615d5a;">Xinyu Zhu, </span><span style="color:#615d5a;">Mengzhou Xia, </span><span style="color:#615d5a;">Zhepei Wei, </span><strong>Wei-Lin Chen, </strong><span style="color:#615d5a;">Danqi Chen, </span><span style="color:#615d5a;">Yu Meng</span></i>
      <br>
      <em>NeurIPS 2025</em>
      <br>
      <a href='https://arxiv.org/pdf/2506.01347' target='_blank'>arXiv</a> /
      <a href='https://x.com/tianhongzxy/status/1929596099154633036' target='_blank'>thread</a>
    </td>
  </tr>
  <tr>
    <td style="padding:8px 2.5%;width:100%;vertical-align:middle">
      <span class="papertitle">Evaluating Large Language Models as Expert Annotators</span>
      <br>
      <i><span style="color:#615d5a;">Yu-Min Tseng, </span><strong>Wei-Lin Chen, </strong><span style="color:#615d5a;">Chung-Chi Chen, </span><span style="color:#615d5a;">Hsin-Hsi Chen</span></i>
      <br>
      <em>COLM 2025</em>
      <br>
      <a href='https://arxiv.org/pdf/2508.07827' target='_blank'>arXiv</a> /
      <a href='https://x.com/ym_tseng/status/1975775205000970242' target='_blank'>thread</a>
    </td>
  </tr>
  <tr>
    <td style="padding:8px 2.5%;width:100%;vertical-align:middle">
      <span class="papertitle">InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales</span>
      <br>
      <i><span style="color:#615d5a;">Zhepei Wei, </span><strong>Wei-Lin Chen</strong><span style="color:#615d5a;">, Yu Meng</span></i>
      <br>
      <em>ICLR 2025</em>
      <br>
      <a href='https://arxiv.org/pdf/2406.13629' target='_blank'>arXiv</a> /
      <a href='https://x.com/weizhepei/status/1803992285899620837' target='_blank'>thread</a>
    </td>
  </tr>
  <tr>
    <td style="padding:8px 2.5%;width:100%;vertical-align:middle">
      <span class="papertitle">Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization</span>
      <br>
      <i><span style="color:#615d5a;">Yu-Min Tseng\(^*\), Yu-Chao Huang\(^*\), Teng-Yun Hsiao\(^*\),</span><strong>Wei-Lin Chen\(^*\)</strong><span style="color:#615d5a;">, Chao-Wei Huang, Yu Meng, Yun-Nung Chen</span></i>
      <br>
      <em>EMNLP 2024 Findings</em>
      <br>
      <a href='https://arxiv.org/pdf/2406.01171' target='_blank'>arXiv</a> /
      <a href='https://github.com/MiuLab/PersonaLLM-Survey' target='_blank'>repo</a>
    </td>
  </tr>
  <tr>
    <td style="padding:8px 2.5%;width:100%;vertical-align:middle">
      <span class="papertitle">Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations</span>
      <br>
      <i><strong>Wei-Lin Chen\(^*\)</strong><span style="color:#615d5a;">, Cheng-Kuang Wu\(^*\), Yun-Nung Chen, Hsin-Hsi Chen</span></i>
      <br>
      <em>EMNLP 2023</em>
      <br>
      <a href='https://arxiv.org/pdf/2305.15035.pdf' target='_blank'>arXiv</a> /
      <a href='https://drive.google.com/file/d/1394T7uNCOYMrQ8UM7FhbzRh1Bvu0062V/view?usp=drive_link' target='_blank'>poster</a>
    </td>
  </tr>
</tbody></table>

<div style="margin-top: 50px;">
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=275&t=tt&d=SSNzpf-n9j1ATVLYu-3_NOAffWWJRF98QxIrruH-JoA&co=98d4ff&ct=ffffff&cmo=919191'></script>
</div>
